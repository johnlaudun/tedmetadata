{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Transcripts\n",
    "\n",
    "In this notebook, we are going to parse the downloaded transcripts found in the directory of the same name. This script was originally written to use the `requests` library and to fetch the transcripts from the website itself. When that failed, I used `wget` and a list of URLs to download the html files, which are here ordered by their place in the list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate a merge, I need to elicit a **key** that these files share with other CSVs. I think the easiest is going to be to focus on the **`public_URL`**, and it looks like the following HTML will give me what I need:\n",
    "\n",
    "    <link rel=\"canonical\" href=\"https://www.ted.com/talks/al_gore_on_averting_climate_crisis/transcript\" />\n",
    "\n",
    "I can use BeautifulSoup to locate the `link` tag and then the `rel=\"canonical\"` attribute, and then I'll need to chomp `/transcript` off the string.\n",
    "\n",
    "Sounds doable, yeah?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on in one line of code below, which I built up over a series of trials. To be clear, I wanted to get it down to one-line to make the `parse` function more compact. Here's a description of what happens in the series of things that happen below.\n",
    "\n",
    "Once `thesoup` object is created, `find` finds the first instance of the `<link>` tag where the `\"rel\"` attribute has the value \"`canonical`\". The `['href']` acts, as I understand it, like an index to a list, pulling out that href value, which in the case of `transcript.0` is:\n",
    "\n",
    "    https://www.ted.com/talks/al_gore_on_averting_climate_crisis/transcript\n",
    "\n",
    "We don't want the `/transcript` part of this string, since we will be merging on the main URL. Some googling and stackoverflowing revealed that the `split` method is faster than any regex we could use. Fortunately, all we needed was to peel off the part after the last slant, so this use of `rsplit('/', 1)` (reverse split) goes one slant back from the end and creates a list with two items. We want the first item in that list, and the zeroth index, `[0]`, gives us that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking through the code to get the link tag above\n",
    "\n",
    "# Load HTML into a BS4 object\n",
    "thesoup = BeautifulSoup(open(\"./transcripts/transcript.0\"), \"html5lib\")\n",
    "\n",
    "public_html = thesoup.find(\"link\", {'rel': 'canonical'})['href'].rsplit('/', 1)[0]\n",
    "print(public_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Import libraries\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "import pandas, re, csv, os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Define functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def parse(thesoup):\n",
    "    public_URL = thesoup.find(\"link\", {'rel': 'canonical'})['href'].rsplit('/', 1)[0]\n",
    "    for tag in thesoup.find_all(\"meta\"):\n",
    "        if tag.get(\"name\", None) == \"author\":\n",
    "            speaker = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"duration\":\n",
    "            duration = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"uploadDate\":\n",
    "            uploaded = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"interactionCount\":\n",
    "            views = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"description\":\n",
    "            description = tag.get(\"content\", None)\n",
    "    strung = ''.join([div.text for div in \n",
    "            thesoup.findAll(\"div\", {\"class\": \"Grid__cell flx-s:1 p-r:4\"})])\n",
    "    text   = re.sub(r\"[\\t]\", \"\", strung).replace(\"\\n\", \" \")\n",
    "    return public_URL, speaker, duration, uploaded, views, description, text\n",
    "\n",
    "def to_csv(pth, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer. \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"public_URL\", \"speaker\", \"duration\", \"uploaded\", \"views\", \n",
    "                     \"xss_description\", \"text\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                # parse the file and write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"html5lib\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1c661179b4a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# =-=-=-=-=-=-=-=-=-=-=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./transcripts\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"transcripts.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-26f41c489c19>\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(pth, out)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# parse the file and write the data to a row.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html5lib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-26f41c489c19>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(thesoup)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthesoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpublic_URL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthesoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"link\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'rel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'canonical'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthesoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"author\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Write the CSV\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "to_csv(\"./transcripts\",\"transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# LOAD the CSV into a Pandas dataframe to check our work\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# Let python create the column names list:\n",
    "with open('./test_transcripts.csv') as f:\n",
    "    colnames = f.readline().strip().split(\",\")\n",
    "\n",
    "# Now will import the csv as a dataframe with the column names specified\n",
    "TEDtalks = pandas.read_csv('./test_transcripts.csv', names=colnames)\n",
    "\n",
    "# Check for success:\n",
    "TEDtalks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URLs = TEDtalks.public_URL.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(URLs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
