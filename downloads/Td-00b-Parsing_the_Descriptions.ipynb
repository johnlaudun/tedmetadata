{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Descriptions\n",
    "\n",
    "In this notebook, we are going to parse the main pages downloaded and saved in the `descriptions` directory.\n",
    "\n",
    "Like the transcripts, we are going to use the `public_URL` as the key to merge the CSVs: we are probably going to use the `pandas` dataframe merge functionality to do this, but there may very well be something in the `csv` library. \n",
    "\n",
    "    <link rel=\"canonical\" href=\"https://www.ted.com/talks/al_gore_on_averting_climate_crisis\" />\n",
    "I can re-use the BeautifulSoup code I wrote for the transcripts to locate the `link` tag with the `rel=\"canonical\"` attribute, but I won't need to delete trailing `/transcript`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Import libraries\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "import pandas, re, csv, os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ted.com/talks/al_gore_on_averting_climate_crisis\n"
     ]
    }
   ],
   "source": [
    "# Walking through the code to get the link tag above\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "#  LOAD the file into a BS4 object\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "thesoup = BeautifulSoup(open(\"./descriptions/al_gore_on_averting_climate_crisis\"), \"html5lib\")\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# public_URL\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "public_URL = thesoup.find(\"link\", {'rel': 'canonical'})['href']\n",
    "print(public_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Read the HTML & get the section we want\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "soup = BeautifulSoup(text, \"html5lib\")\n",
    "my_list = [i.string.lstrip('q(\"talkPage.init\", {\\n\\t\"el\": \"[data-talk-page]\",\\n\\t \"__INITIAL_DATA__\":')\n",
    "           .rstrip('})')\n",
    "           for i in soup.select('script') \n",
    "           if i.string and i.string.startswith('q')]\n",
    "\n",
    "pre_json = '{\"' + \"\".join(my_list)\n",
    "my_json = json.loads(pre_json)\n",
    "\n",
    "out_slug = my_json['slug']\n",
    "out_vcount = my_json['viewed_count']\n",
    "out_event = my_json['event']\n",
    "\n",
    "talks_listed = str(my_json['talks']).split(\",\")\n",
    "\n",
    "properties = \"filmed,published\" # No spaces between terms!\n",
    "regex_list = [\".*(\"+i+\").*\" for i in properties.split(\",\")]\n",
    "\n",
    "matches = []\n",
    "for e in regex_list:\n",
    "    filtered = filter(re.compile(e).match, talks_listed)\n",
    "    indexed = \"\".join(filtered).split(\":\")[1]\n",
    "    matches.append(indexed)\n",
    "\n",
    "out_filmed =  matches[0]\n",
    "out_published = matches[1]\n",
    "\n",
    "print(out_slug, out_vcount, out_event, out_filmed, out_published)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm a little concerned that the code above appears to return a list. BS's `.text` method doesn't appear to work if I append it. For now, we'll see what happens with a test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Define functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def parse(thesoup):\n",
    "    public_URL = thesoup.find_all(\"link\", {'rel': 'canonical'})\n",
    "    for tag in thesoup.find_all(\"meta\"):\n",
    "        if tag.get(\"name\", None) == \"author\":\n",
    "            speaker = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"duration\":\n",
    "            duration = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"uploadDate\":\n",
    "            uploaded = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"interactionCount\":\n",
    "            views = tag.get(\"content\", None)\n",
    "        if tag.get(\"itemprop\", None) == \"description\":\n",
    "            description = tag.get(\"content\", None)\n",
    "    strung = ''.join([div.text for div in \n",
    "            thesoup.findAll(\"div\", {\"class\": \"Grid__cell flx-s:1 p-r:4\"})])\n",
    "    text   = re.sub(r\"[\\t]\", \"\", strung).replace(\"\\n\", \" \")\n",
    "    return public_URL, speaker, duration, uploaded, views, description, text\n",
    "\n",
    "def to_csv(pth, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer. \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"public_URL\", \"speaker\", \"duration\", \"uploaded\", \"views\", \n",
    "                     \"xss_description\", \"text\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                # parse the file and write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"html5lib\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Write the CSV\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "to_csv(\"./test\",\"test_transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# LOAD the CSV into a Pandas dataframe to check our work\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# Let python create the column names list:\n",
    "with open('./test_transcripts.csv') as f:\n",
    "    colnames = f.readline().strip().split(\",\")\n",
    "\n",
    "# Now will import the csv as a dataframe with the column names specified\n",
    "TEDtalks = pandas.read_csv('./test_transcripts.csv', names=colnames)\n",
    "\n",
    "# Check for success:\n",
    "TEDtalks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptions = TEDtalks.description.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(descriptions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
