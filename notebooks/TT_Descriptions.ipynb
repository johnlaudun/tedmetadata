{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ted Talk Descriptions <a id='contents'></a>\n",
    "\n",
    "This notebook has the following sections:\n",
    "\n",
    "* [`BeautifulSoup`](#beautifulsoup) - code used to clean the downloaded files and save to `csv`. (The file is already saved, so this cell does not need to be run again.)\n",
    "* [`pandas`](#pandas) - run this cell to load the csv file into three lists: titles, views, descriptions. \n",
    "* [Jaccard Matrices](#jaccard) - \n",
    " - [John]() - \n",
    " - [Katherine](#katherine) - this one needs to be run to load the matrix into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BeautifulSoup`<a id='beautifulsoup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# title: <span class=\"player-hero__title__content\">\n",
    "# description: <p class=\"talk-description\" lang=\"en\">\n",
    "# views: <span class=\"talk-sharing__value\"> 96,013 </span>\n",
    "\n",
    "\n",
    "def parse(soup):\n",
    "    # both title and views are can be parsed in separate tags.\n",
    "    title = soup.find('span', {'class' : \"player-hero__title__content\"}).text.strip('\\n')\n",
    "    views = soup.find('span', {'class' : \"talk-sharing__value\"}).text.strip('\\n')\n",
    "    descr = soup.find('p', {'class' : \"talk-description\"}).text.strip('\\n')\n",
    "    return title.strip(), views, descr\n",
    "\n",
    "def to_csv(pth, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer.\n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"title\", \"views\", \"descr\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                print(html)\n",
    "                # parse the file and write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"lxml\")))\n",
    "\n",
    "to_csv(\"./html_files/descriptions/\",\".</data/descriptions-2.csv\") # This is to the test directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pandas`<a id='pandas'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "colnames = ['title', 'views' , 'descr']\n",
    "data = pandas.read_csv('./data/descriptions-2.csv', names=colnames)\n",
    "titles = data.title.tolist()\n",
    "views = data.views.tolist()\n",
    "descriptions = data.descr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Trials <a id='jaccard'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "tokenize = lambda doc: doc.lower().split()\n",
    " \n",
    "sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)\n",
    "sklearn_representation = sklearn_tfidf.fit_transform(descriptions)\n",
    "#print(sklearn_representation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To get a list of punctuation:\n",
    "\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To find out the ordinal of a particular vexing character:\n",
    "\n",
    "somewords = descriptions[2]\n",
    "print(ord(somewords(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### John's Attempt at a Jaccard Matrix <a id='john'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "\n",
    "def ourtokens(ourstring):\n",
    "    \n",
    "    stoplist = set(get_stop_words('en'))\n",
    "    finalList = []\n",
    "    \n",
    "    wordList = ourstring.lower().split()\n",
    "    for i in range(len(wordList)):\n",
    "        #wordList[i] = re.sub('[^a-zA-Z\\']', '', wordList[i]).strip(chr(8212)) \n",
    "        #NOTE: the above left spaces and added empty strings\n",
    "        \n",
    "        no_punc = wordList[i].strip(string.punctuation) #remove most punctuation\n",
    "        no_emphwhatever = no_punc.strip(chr(8212)) # remove that weirdness\n",
    "        no_num = no_emphwhatever.strip(string.digits) #remove numbers\n",
    "        \n",
    "        if (len(no_num) > 0) and (no_num not in stoplist): # Requires stop_words\n",
    "            # First conditional stops empty strings from being added\n",
    "            finalList.append(no_num)\n",
    "            \n",
    "    return finalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021739130434782608"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    #print(intersection)\n",
    "    union = set(query).union(set(document))\n",
    "    #print(union)\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "jaccard_similarity(ourtokens(descriptions[1]), ourtokens(descriptions[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katherine's Kreation of a Jaccard Matrix <a id='katherine'></a> [[contents](#contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows completed\n",
      "100 rows completed\n",
      "200 rows completed\n",
      "300 rows completed\n",
      "400 rows completed\n",
      "500 rows completed\n",
      "600 rows completed\n",
      "700 rows completed\n",
      "800 rows completed\n",
      "900 rows completed\n",
      "1000 rows completed\n",
      "1100 rows completed\n",
      "1200 rows completed\n",
      "1300 rows completed\n",
      "1400 rows completed\n",
      "1500 rows completed\n",
      "1600 rows completed\n",
      "1700 rows completed\n",
      "1800 rows completed\n",
      "1900 rows completed\n",
      "2000 rows completed\n",
      "2100 rows completed\n",
      "2200 rows completed\n"
     ]
    }
   ],
   "source": [
    "# Create des_word_lists \n",
    "des_word_lists = []\n",
    "for i in range(len(descriptions)):\n",
    "    # Create list of words for each description\n",
    "    words = ourtokens(descriptions[i])\n",
    "    des_word_lists.append({'descriptions': descriptions[i], 'words': words})\n",
    "    \n",
    "    # Tells you where you are in the rows\n",
    "    if (i % 100) == 0:\n",
    "        print(str(i) + \" rows completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the new CSV\n",
    "import csv\n",
    "\n",
    "with open('.</data/desPlusWords-2.csv', 'w') as desfile:\n",
    "    fields = ['descriptions', 'words']\n",
    "    writer = csv.DictWriter(desfile, fieldnames = fields)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    writer.writerows(des_word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# Load deswordlists from CSV\n",
    "colnames = ['descriptions', 'words']\n",
    "data = pandas.read_csv('./data/desPlusWords-2.csv', names=colnames)\n",
    "descriptions = data.descriptions.tolist()\n",
    "words = data.words.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows completed\n",
      "100 rows completed\n",
      "200 rows completed\n",
      "300 rows completed\n",
      "400 rows completed\n",
      "500 rows completed\n",
      "600 rows completed\n",
      "700 rows completed\n",
      "800 rows completed\n",
      "900 rows completed\n",
      "1000 rows completed\n",
      "1100 rows completed\n",
      "1200 rows completed\n",
      "1300 rows completed\n",
      "1400 rows completed\n",
      "1500 rows completed\n",
      "1600 rows completed\n",
      "1700 rows completed\n",
      "1800 rows completed\n",
      "1900 rows completed\n",
      "2000 rows completed\n",
      "2100 rows completed\n",
      "2200 rows completed\n"
     ]
    }
   ],
   "source": [
    "Ndes = len(des_word_lists)\n",
    "\n",
    "# From http://stackoverflow.com/questions/568962/how-do-i-create-an-empty-array-matrix-in-numpy\n",
    "jac_mat = numpy.zeros(shape=(Ndes,Ndes))\n",
    "\n",
    "for i in range(Ndes):\n",
    "    if (i % 100) == 0:\n",
    "        print(str(i) + \" rows completed\")  \n",
    "    \n",
    "    # Start the pairwise computations\n",
    "    \n",
    "    for j in range((i+1),Ndes):\n",
    "        # Pull the ith and jth document\n",
    "        doc_i = des_word_lists[i]['words']\n",
    "        doc_j = des_word_lists[j]['words']\n",
    "        \n",
    "        # Get the Jaccard similarity\n",
    "        jac_ij = jaccard_similarity(doc_i, doc_j)\n",
    "        \n",
    "        # Since the Jaccard will be the same between i and j as it will between\n",
    "        # j and i, we set JAC_MAT[i,j] and JAC_MAT[j,i] to be the same value\n",
    "        jac_mat[i,j] = jac_ij\n",
    "        jac_mat[j,i] = jac_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This block find the maximum for the matrix\n",
    "\n",
    "# Initialize the max to be zero. \n",
    "mat_max = 0\n",
    "\n",
    "# Loop over all the rows\n",
    "for i in range(Ndes):\n",
    "    # Find the maximum for each row\n",
    "    row_max = max(jac_mat[i])\n",
    "    \n",
    "    # Check if the current row's maximum is higher than the current MAT_MAX.\n",
    "    # If the row maximum is bigger, then set MAT_MAX to the row maximum.\n",
    "    if row_max > mat_max:\n",
    "        mat_max = row_max\n",
    "\n",
    "print(mat_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jac_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b4cb161c9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjac_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jac_mat' is not defined"
     ]
    }
   ],
   "source": [
    "jac_mean = jac_mat.mean()\n",
    "print(jac_mean, mat_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The mean is {}, and the max is {}.\".format(jac_mean, mat_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Little Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "micro_jac = jac_mat[0:10,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(micro_jac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Network Woods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "micro = nx.from_numpy_matrix(micro_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(G.nodes()), len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos = nx.spring_layout(micro)\n",
    "nx.draw(micro, pos)\n",
    "plt.savefig('./outputs/micro_jac.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert array to DF\n",
    "# add node labels to the DF\n",
    "# save DF to CSV\n",
    "# nx.write_gexf(G,\"descr-jac.gexf\")\n",
    "nx.write_weighted_edgelist(G, \"./outputs/jacmat.edges\", delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Trimming a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove = [node for node, degree in G.degree().items() if degree <= 2]\n",
    "gmt2 = G.remove_nodes_from(remove)\n",
    "print(len(gmt2.nodes()), len(gmt2.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove = [node for node, degree in G.degree().items() if degree <= 1]\n",
    "gmt1 = G.remove_nodes_from(remove)\n",
    "#print(len(gmt1.nodes()), len(gmt1.edges()))\n",
    "gmt1.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2210"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print([node for node, degree in G.degree().items() if degree > 1])\n",
    "[node for node, degree in G.degree().items() if degree > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SEE: http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "column_labels = titles\n",
    "row_labels = titles\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(jac_mat, cmap=plt.cm.jet)\n",
    "colorbar()\n",
    "# OPTIONS to consider later\n",
    "# put the major ticks at the middle of each cell\n",
    "#ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "#ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "#ax.invert_yaxis()\n",
    "#ax.xaxis.tick_top()\n",
    "\n",
    "#ax.set_xticklabels(row_labels, minor=False)\n",
    "#ax.set_yticklabels(column_labels, minor=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `networkx` sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pg = play graph\n",
    "pg = nx.Graph()\n",
    "pg.add_edge(1,2)\n",
    "pg.add_edge(1,3)\n",
    "pg.add_edge(1,4)\n",
    "pg.add_edge(2,3)\n",
    "pg.add_edge(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pg.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.draw(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove = [node for node, degree in pg.degree().items() if degree <= 2]\n",
    "print(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pg.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pg.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pg.remove_nodes_from(remove)\n",
    "print(pg.nodes(), pg.edges(), pg.degree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Drawing Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From: https://www.udacity.com/wiki/creating-network-graphs-with-python\n",
    "\n",
    "def draw_graph(graph, labels=None, graph_layout='shell',\n",
    "               node_size=1600, node_color='blue', node_alpha=0.3,\n",
    "               node_text_size=12,\n",
    "               edge_color='blue', edge_alpha=0.3, edge_tickness=1,\n",
    "               edge_text_pos=0.3,\n",
    "               text_font='sans-serif'):\n",
    "\n",
    "    # create networkx graph\n",
    "    G=nx.Graph()\n",
    "\n",
    "    # add edges\n",
    "    for edge in graph:\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "\n",
    "    # these are different layouts for the network you may try\n",
    "    # shell seems to work best\n",
    "    if graph_layout == 'spring':\n",
    "        graph_pos=nx.spring_layout(G)\n",
    "    elif graph_layout == 'spectral':\n",
    "        graph_pos=nx.spectral_layout(G)\n",
    "    elif graph_layout == 'random':\n",
    "        graph_pos=nx.random_layout(G)\n",
    "    else:\n",
    "        graph_pos=nx.shell_layout(G)\n",
    "\n",
    "    # draw graph\n",
    "    nx.draw_networkx_nodes(G,graph_pos,node_size=node_size, \n",
    "                           alpha=node_alpha, node_color=node_color)\n",
    "    nx.draw_networkx_edges(G,graph_pos,width=edge_tickness,\n",
    "                           alpha=edge_alpha,edge_color=edge_color)\n",
    "    nx.draw_networkx_labels(G, graph_pos,font_size=node_text_size,\n",
    "                            font_family=text_font)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = range(len(graph))\n",
    "\n",
    "    edge_labels = dict(zip(graph, labels))\n",
    "    nx.draw_networkx_edge_labels(G, graph_pos, edge_labels=edge_labels, \n",
    "                                 label_pos=edge_text_pos)\n",
    "\n",
    "    # show graph\n",
    "    plt.show()\n",
    "\n",
    "graph = [(0, 1), (1, 5), (1, 7), (4, 5), (4, 8), (1, 6), (3, 7), (5, 9),\n",
    "         (2, 4), (0, 4), (2, 5), (3, 6), (8, 9)]\n",
    "\n",
    "# you may name your edge labels\n",
    "labels = map(chr, range(65, 65+len(graph)))\n",
    "#draw_graph(graph, labels)\n",
    "\n",
    "# if edge labels is not specified, numeric labels (0, 1, 2...) will be used\n",
    "draw_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import string\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "\n",
    "# Load descriptions and titles\n",
    "colnames = ['title', 'views' , 'descr']\n",
    "data = pandas.read_csv('./data/descriptions-2.csv', names=colnames)\n",
    "titles = data.title.tolist()\n",
    "views = data.views.tolist()\n",
    "descriptions = data.descr.tolist()\n",
    "\n",
    "# Load deswordlists from CSV\n",
    "colnames = ['descriptions', 'words']\n",
    "data = pandas.read_csv('./data/desPlusWords-2.csv', names=colnames)\n",
    "descriptions = data.descriptions.tolist()\n",
    "words = data.words.tolist()\n",
    "\n",
    "\n",
    "# A couple of functions\n",
    "\n",
    "def ourtokens(ourstring):\n",
    "    \n",
    "    stoplist = set(get_stop_words('en'))\n",
    "    finalList = []\n",
    "    \n",
    "    wordList = ourstring.lower().split()\n",
    "    for i in range(len(wordList)):\n",
    "        #wordList[i] = re.sub('[^a-zA-Z\\']', '', wordList[i]).strip(chr(8212)) \n",
    "        #NOTE: the above left spaces and added empty strings\n",
    "        no_punc = wordList[i].strip(string.punctuation) #remove most punctuation\n",
    "        no_emphwhatever = no_punc.strip(chr(8212)) # remove that weirdness\n",
    "        no_num = no_emphwhatever.strip(string.digits) #remove numbers\n",
    "        if (len(no_num) > 0) and (no_num not in stoplist): # Requires stop_words\n",
    "            # First conditional stops empty strings from being added\n",
    "            finalList.append(no_num)            \n",
    "    return finalList\n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    #print(intersection)\n",
    "    union = set(query).union(set(document))\n",
    "    #print(union)\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "# Create JACCARD MATRIX\n",
    "# From http://stackoverflow.com/questions/568962/how-do-i-create-an-empty-array-matrix-in-numpy\n",
    "Ndes = len(des_word_lists)\n",
    "jac_mat = numpy.zeros(shape=(Ndes,Ndes))\n",
    "for i in range(Ndes):\n",
    "    if (i % 100) == 0:\n",
    "        print(str(i) + \" rows completed\")    \n",
    "    # Start the pairwise computations\n",
    "    for j in range((i+1),Ndes):\n",
    "        # Pull the ith and jth document\n",
    "        doc_i = des_word_lists[i]['words']\n",
    "        doc_j = des_word_lists[j]['words']\n",
    "        # Get the Jaccard similarity\n",
    "        jac_ij = jaccard_similarity(doc_i, doc_j)\n",
    "        # Since the Jaccard will be the same between i and j as it will between\n",
    "        # j and i, we set JAC_MAT[i,j] and JAC_MAT[j,i] to be the same value\n",
    "        jac_mat[i,j] = jac_ij\n",
    "        jac_mat[j,i] = jac_ij"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
